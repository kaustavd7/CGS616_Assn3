{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaustavd7/CGS616_Assn3/blob/main/Modelling_speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "m38Qf2uAuABZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuQW5Vw7bOzN",
        "outputId": "97657ecb-ed1e-4640-893d-497d73386db8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechAnxietyDataset(Dataset):\n",
        "    def __init__(self, label_csv, feature_dir, max_seq_len=50):\n",
        "        self.data = pd.read_csv(label_csv)\n",
        "        self.feature_dir = feature_dir\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def pad_or_truncate(self, arr, max_len):\n",
        "        if len(arr) > max_len:\n",
        "            return arr[:max_len]\n",
        "        elif len(arr) < max_len:\n",
        "            pad = np.zeros((max_len - len(arr), arr.shape[1]))\n",
        "            return np.vstack([arr, pad])\n",
        "        return arr\n",
        "\n",
        "    def load_clean_csv(self, path):\n",
        "          df = pd.read_csv(path, delimiter=';')\n",
        "          df = df.drop(columns=[df.columns[0]], axis = 1, errors='ignore')\n",
        "\n",
        "          df = df.loc[:, ~df.columns.str.contains('^Unnamed')]  # Drop all Unnamed columns\n",
        "          return df.values.astype(np.float32)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        pid = str(row[\"Participant\"])\n",
        "        folder = os.path.join(self.feature_dir, f\"{pid}_features\")\n",
        "\n",
        "        mfcc = self.load_clean_csv(os.path.join(folder, f\"{pid}_OpenSMILE2.3.0_mfcc.csv\"))\n",
        "        # mfcc = mfcc.drop(columns = [mfcc.columns[0]]).values.astype(np.float32)\n",
        "\n",
        "        egemaps = self.load_clean_csv(os.path.join(folder, f\"{pid}_OpenSMILE2.3.0_egemaps.csv\"))\n",
        "        # egemaps = egemaps.drop(columns = [egemaps.columns[0]]).values.astype(np.float32)\n",
        "\n",
        "        mfcc = self.pad_or_truncate(mfcc, self.max_seq_len)\n",
        "        egemaps = self.pad_or_truncate(egemaps, self.max_seq_len)\n",
        "        return {\n",
        "            \"mfcc\": torch.tensor(mfcc),\n",
        "            \"egemaps\": torch.tensor(egemaps),\n",
        "            \"anxiety\": torch.tensor(row[\"Anxiety_severity\"], dtype=torch.float32),\n",
        "            \"ptsd\": torch.tensor(row[\"PTSD_label\"], dtype=torch.float32)\n",
        "        }"
      ],
      "metadata": {
        "id": "KQuexofQId05"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalModalityEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, lstm_hidden=64, latent_dim=64, num_layers=1, dropout=0.3):\n",
        "        super(TemporalModalityEncoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, lstm_hidden, num_layers=num_layers,\n",
        "                            batch_first=True, dropout=dropout, bidirectional=True)\n",
        "        self.project = nn.Sequential(\n",
        "            nn.Linear(lstm_hidden * 2, latent_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        hn = hn.transpose(0, 1).reshape(x.size(0), -1)\n",
        "        return self.project(hn)\n",
        "\n",
        "class FusionModule(nn.Module):\n",
        "    def __init__(self, input_dim, fusion_dim=128, dropout=0.3):\n",
        "        super(FusionModule, self).__init__()\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(input_dim, fusion_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fusion(x)\n",
        "\n",
        "class AnxietyPTSDModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AnxietyPTSDModel, self).__init__()\n",
        "        self.mfcc_encoder = TemporalModalityEncoder(input_dim=39)\n",
        "        self.egemap_encoder = TemporalModalityEncoder(input_dim=88)\n",
        "\n",
        "        self.fusion = FusionModule(input_dim=64 * 2)\n",
        "        self.anxiety_head = nn.Linear(128, 1)\n",
        "        self.ptsd_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, mfcc, egemap):\n",
        "        z1 = self.mfcc_encoder(mfcc)\n",
        "        z2 = self.egemap_encoder(egemap)\n",
        "\n",
        "        fused = self.fusion(torch.cat([z1, z2], dim=-1))\n",
        "        anxiety_pred = self.anxiety_head(fused)\n",
        "        ptsd_pred = torch.sigmoid(self.ptsd_head(fused))\n",
        "\n",
        "        return anxiety_pred.squeeze(), ptsd_pred.squeeze()\n",
        "\n",
        "def multitask_loss(anxiety_pred, anxiety_true, ptsd_pred, ptsd_true, alpha=0.5):\n",
        "    loss_reg = F.mse_loss(anxiety_pred, anxiety_true)\n",
        "    loss_cls = F.binary_cross_entropy(ptsd_pred, ptsd_true)\n",
        "    return loss_reg + alpha * loss_cls"
      ],
      "metadata": {
        "id": "0IXBiUDxYCi7"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader):\n",
        "        mfcc = batch[\"mfcc\"].to(device)\n",
        "        egemaps = batch[\"egemaps\"].to(device)\n",
        "        anxiety = batch[\"anxiety\"].to(device)\n",
        "        ptsd = batch[\"ptsd\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        anx_pred, ptsd_pred = model(mfcc, egemaps)\n",
        "        loss = multitask_loss(anx_pred, anxiety, ptsd_pred, ptsd)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            mfcc = batch[\"mfcc\"].to(device)\n",
        "            egemaps = batch[\"egemaps\"].to(device)\n",
        "            anxiety = batch[\"anxiety\"].to(device)\n",
        "            ptsd = batch[\"ptsd\"].to(device)\n",
        "\n",
        "            anx_pred, ptsd_pred = model(mfcc, egemaps)\n",
        "            loss = multitask_loss(anx_pred, anxiety, ptsd_pred, ptsd)\n",
        "            total_loss += loss.item()\n",
        "            all_preds.extend(ptsd_pred.round().cpu().tolist())\n",
        "            all_labels.extend(ptsd.cpu().tolist())\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    return total_loss / len(dataloader), f1\n"
      ],
      "metadata": {
        "id": "G1Xt-HmpYJ2c"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/HCC_Project'\n",
        "data_path = os.path.join(path, 'speech_features')\n",
        "label_path = os.path.join(path, 'labels/Final_detailed_labels_train.csv')\n",
        "\n",
        "\n",
        "dataset = SpeechAnxietyDataset(label_path,data_path)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "\n",
        "model = AnxietyPTSDModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    train_loss = train(model, train_loader, optimizer, device)\n",
        "    val_loss, val_f1 = evaluate(model, val_loader, device)\n",
        "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | PTSD F1: {val_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "sZU0ZAVPbC8l",
        "outputId": "50bc3b48-9590-42d7-8f6b-11db61ed8e4b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\n",
            "  0%|          | 0/7 [00:30<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "input.size(-1) must be equal to input_size. Expected 39, got 40",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-a5fa7d7a2ecb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | PTSD F1: {val_f1:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-173e24a27cdc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0manx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptsd_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0megemaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultitask_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manxiety\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptsd_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptsd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-78958e4d7ed9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mfcc, egemap)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0megemap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0megemap_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0megemap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-78958e4d7ed9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                 )\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m     ):\n\u001b[0;32m-> 1002\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         self.check_hidden_size(\n\u001b[1;32m   1004\u001b[0m             \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    312\u001b[0m             )\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0;34mf\"input.size(-1) must be equal to input_size. Expected {self.input_size}, got {input.size(-1)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 39, got 40"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "TFRUolZ7K-TC"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LEN = 50\n",
        "MFCC_DIM = 40\n",
        "EGEMAPS_DIM = 24\n",
        "LABEL_CSV = \"Final_detailed_labels_train.csv\"\n",
        "FEATURE_DIR = \"speech_features\"\n",
        "path = '/content/drive/MyDrive/HCC_Project'\n",
        "data_path = os.path.join(path, 'speech_features')\n",
        "label_path = os.path.join(path, 'labels/Final_detailed_labels_train.csv')"
      ],
      "metadata": {
        "id": "bRrvrfgiLAOK"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_pad_features(pid):\n",
        "    folder = os.path.join(data_path, f\"{pid}_features\")\n",
        "\n",
        "    def load_csv_clean(path, expected_dim):\n",
        "        df = pd.read_csv(path, delimiter=';')\n",
        "        df.drop([df.columns[0]], axis = 1, inplace = True)\n",
        "        df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
        "        arr = df.values.astype(np.float32)\n",
        "        if arr.shape[0] > MAX_SEQ_LEN:\n",
        "            arr = arr[:MAX_SEQ_LEN]\n",
        "        elif arr.shape[0] < MAX_SEQ_LEN:\n",
        "            pad = np.zeros((MAX_SEQ_LEN - arr.shape[0], expected_dim), dtype=np.float32)\n",
        "            arr = np.vstack([arr, pad])\n",
        "        return arr\n",
        "\n",
        "    mfcc = load_csv_clean(os.path.join(folder, f\"{pid}_OpenSMILE2.3.0_mfcc.csv\"), MFCC_DIM)\n",
        "    egemaps = load_csv_clean(os.path.join(folder, f\"{pid}_OpenSMILE2.3.0_egemaps.csv\"), EGEMAPS_DIM)\n",
        "    return mfcc, egemaps\n"
      ],
      "metadata": {
        "id": "xrzQDD5qLBxy"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset(label_csv, batch_size=16):\n",
        "    df = pd.read_csv(label_csv)\n",
        "    pids = df[\"Participant\"].tolist()\n",
        "    anxiety = df[\"Anxiety_severity\"].tolist()\n",
        "    ptsd = df[\"PTSD_label\"].tolist()\n",
        "\n",
        "    mfcc_data, egemaps_data = [], []\n",
        "    for pid in pids:\n",
        "        mfcc, egemaps = load_and_pad_features(pid)\n",
        "        mfcc_data.append(mfcc)\n",
        "        egemaps_data.append(egemaps)\n",
        "\n",
        "    X_mfcc = np.stack(mfcc_data)\n",
        "    X_egemaps = np.stack(egemaps_data)\n",
        "    y_anx = np.array(anxiety, dtype=np.float32)\n",
        "    y_ptsd = np.array(ptsd, dtype=np.float32)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(((X_mfcc, X_egemaps), (y_anx, y_ptsd)))\n",
        "    return dataset.shuffle(256).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Eka5J6pqLDyy"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    mfcc_input = tf.keras.Input(shape=(MAX_SEQ_LEN, MFCC_DIM))\n",
        "    egemaps_input = tf.keras.Input(shape=(MAX_SEQ_LEN, EGEMAPS_DIM))\n",
        "\n",
        "    x1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False))(mfcc_input)\n",
        "    x2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False))(egemaps_input)\n",
        "\n",
        "    fused = tf.keras.layers.Concatenate()([x1, x2])\n",
        "    fused = tf.keras.layers.Dense(128, activation='relu')(fused)\n",
        "    fused = tf.keras.layers.Dropout(0.3)(fused)\n",
        "\n",
        "    out_anxiety = tf.keras.layers.Dense(1, name=\"anxiety_output\")(fused)\n",
        "    out_ptsd = tf.keras.layers.Dense(1, activation='sigmoid', name=\"ptsd_output\")(fused)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[mfcc_input, egemaps_input], outputs=[out_anxiety, out_ptsd])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "sgsG8tQ6LGAT"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_ds = create_tf_dataset(label_path)\n",
        "train_ds = full_ds.take(int(0.8 * len(full_ds)))\n",
        "val_ds = full_ds.skip(int(0.8 * len(full_ds)))"
      ],
      "metadata": {
        "id": "JgTdTTs1LH2S"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\"anxiety_output\": \"mse\", \"ptsd_output\": \"binary_crossentropy\"},\n",
        "    loss_weights={\"anxiety_output\": 1.0, \"ptsd_output\": 0.5},\n",
        "    metrics={\"ptsd_output\": [\"accuracy\"]}\n",
        ")\n",
        "\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL9sDSUyNGrS",
        "outputId": "e8ed93b2-6097-4918-a73c-62c24305887e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 153ms/step - anxiety_output_loss: 200.9741 - loss: 201.3239 - ptsd_output_accuracy: 0.4698 - ptsd_output_loss: 0.6997 - val_anxiety_output_loss: 98.8189 - val_loss: 101.2052 - val_ptsd_output_accuracy: 0.7407 - val_ptsd_output_loss: 0.5650\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - anxiety_output_loss: 124.5998 - loss: 124.9013 - ptsd_output_accuracy: 0.7330 - ptsd_output_loss: 0.6030 - val_anxiety_output_loss: 37.3144 - val_loss: 41.3663 - val_ptsd_output_accuracy: 0.7778 - val_ptsd_output_loss: 0.5648\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - anxiety_output_loss: 56.1964 - loss: 56.5541 - ptsd_output_accuracy: 0.6292 - ptsd_output_loss: 0.7155 - val_anxiety_output_loss: 39.7716 - val_loss: 41.2122 - val_ptsd_output_accuracy: 0.6667 - val_ptsd_output_loss: 0.6620\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 54.3677 - loss: 54.8352 - ptsd_output_accuracy: 0.5097 - ptsd_output_loss: 0.9350 - val_anxiety_output_loss: 42.5770 - val_loss: 45.0618 - val_ptsd_output_accuracy: 0.7037 - val_ptsd_output_loss: 0.6456\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 34.0949 - loss: 34.5189 - ptsd_output_accuracy: 0.6201 - ptsd_output_loss: 0.8481 - val_anxiety_output_loss: 28.7514 - val_loss: 30.2996 - val_ptsd_output_accuracy: 0.6667 - val_ptsd_output_loss: 0.6159\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 42.2751 - loss: 42.6858 - ptsd_output_accuracy: 0.5594 - ptsd_output_loss: 0.8215 - val_anxiety_output_loss: 34.9464 - val_loss: 37.6813 - val_ptsd_output_accuracy: 0.7407 - val_ptsd_output_loss: 0.5755\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - anxiety_output_loss: 35.5937 - loss: 35.9921 - ptsd_output_accuracy: 0.5735 - ptsd_output_loss: 0.7967 - val_anxiety_output_loss: 31.0469 - val_loss: 30.3492 - val_ptsd_output_accuracy: 0.7778 - val_ptsd_output_loss: 0.5368\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 36.5354 - loss: 36.9062 - ptsd_output_accuracy: 0.5754 - ptsd_output_loss: 0.7416 - val_anxiety_output_loss: 49.3368 - val_loss: 51.4964 - val_ptsd_output_accuracy: 0.6296 - val_ptsd_output_loss: 0.6772\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 37.6809 - loss: 38.1395 - ptsd_output_accuracy: 0.5384 - ptsd_output_loss: 0.9172 - val_anxiety_output_loss: 25.4029 - val_loss: 24.2548 - val_ptsd_output_accuracy: 0.5556 - val_ptsd_output_loss: 0.7638\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - anxiety_output_loss: 31.0853 - loss: 31.4309 - ptsd_output_accuracy: 0.6173 - ptsd_output_loss: 0.6912 - val_anxiety_output_loss: 40.6310 - val_loss: 38.3737 - val_ptsd_output_accuracy: 0.5556 - val_ptsd_output_loss: 0.7669\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 33.6659 - loss: 33.9932 - ptsd_output_accuracy: 0.6955 - ptsd_output_loss: 0.6547 - val_anxiety_output_loss: 27.3802 - val_loss: 28.5029 - val_ptsd_output_accuracy: 0.6667 - val_ptsd_output_loss: 0.6652\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - anxiety_output_loss: 25.4226 - loss: 25.7534 - ptsd_output_accuracy: 0.6540 - ptsd_output_loss: 0.6616 - val_anxiety_output_loss: 20.1243 - val_loss: 21.5960 - val_ptsd_output_accuracy: 0.8148 - val_ptsd_output_loss: 0.5252\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 27.4739 - loss: 27.8888 - ptsd_output_accuracy: 0.5484 - ptsd_output_loss: 0.8297 - val_anxiety_output_loss: 22.9700 - val_loss: 21.9051 - val_ptsd_output_accuracy: 0.7037 - val_ptsd_output_loss: 0.6168\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 22.1050 - loss: 22.4507 - ptsd_output_accuracy: 0.5856 - ptsd_output_loss: 0.6915 - val_anxiety_output_loss: 30.5070 - val_loss: 30.9849 - val_ptsd_output_accuracy: 0.7778 - val_ptsd_output_loss: 0.5469\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 26.8861 - loss: 27.2252 - ptsd_output_accuracy: 0.6926 - ptsd_output_loss: 0.6781 - val_anxiety_output_loss: 15.2859 - val_loss: 15.8212 - val_ptsd_output_accuracy: 0.6667 - val_ptsd_output_loss: 0.6845\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 21.4028 - loss: 21.8340 - ptsd_output_accuracy: 0.4839 - ptsd_output_loss: 0.8624 - val_anxiety_output_loss: 21.3559 - val_loss: 22.3360 - val_ptsd_output_accuracy: 0.7407 - val_ptsd_output_loss: 0.6056\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 15.8146 - loss: 16.1917 - ptsd_output_accuracy: 0.5704 - ptsd_output_loss: 0.7542 - val_anxiety_output_loss: 16.7666 - val_loss: 17.4408 - val_ptsd_output_accuracy: 0.6667 - val_ptsd_output_loss: 0.6141\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - anxiety_output_loss: 19.7573 - loss: 20.1038 - ptsd_output_accuracy: 0.6004 - ptsd_output_loss: 0.6931 - val_anxiety_output_loss: 14.1162 - val_loss: 14.8463 - val_ptsd_output_accuracy: 0.7037 - val_ptsd_output_loss: 0.6083\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 17.9432 - loss: 18.3312 - ptsd_output_accuracy: 0.5978 - ptsd_output_loss: 0.7761 - val_anxiety_output_loss: 21.9510 - val_loss: 23.2146 - val_ptsd_output_accuracy: 0.6296 - val_ptsd_output_loss: 0.6392\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 15.2328 - loss: 15.5971 - ptsd_output_accuracy: 0.6381 - ptsd_output_loss: 0.7285 - val_anxiety_output_loss: 10.4074 - val_loss: 10.4946 - val_ptsd_output_accuracy: 0.7778 - val_ptsd_output_loss: 0.5549\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 17.8503 - loss: 18.3042 - ptsd_output_accuracy: 0.5649 - ptsd_output_loss: 0.9078 - val_anxiety_output_loss: 14.7513 - val_loss: 14.5995 - val_ptsd_output_accuracy: 0.7407 - val_ptsd_output_loss: 0.5747\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 9.0713 - loss: 9.4263 - ptsd_output_accuracy: 0.6028 - ptsd_output_loss: 0.7098 - val_anxiety_output_loss: 7.2564 - val_loss: 7.7231 - val_ptsd_output_accuracy: 0.7037 - val_ptsd_output_loss: 0.5737\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 11.5040 - loss: 11.8179 - ptsd_output_accuracy: 0.6213 - ptsd_output_loss: 0.6278 - val_anxiety_output_loss: 10.3831 - val_loss: 11.1558 - val_ptsd_output_accuracy: 0.6667 - val_ptsd_output_loss: 0.5965\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 9.6385 - loss: 9.9702 - ptsd_output_accuracy: 0.6190 - ptsd_output_loss: 0.6634 - val_anxiety_output_loss: 6.6617 - val_loss: 7.3018 - val_ptsd_output_accuracy: 0.7407 - val_ptsd_output_loss: 0.5170\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - anxiety_output_loss: 9.2524 - loss: 9.5656 - ptsd_output_accuracy: 0.6820 - ptsd_output_loss: 0.6263 - val_anxiety_output_loss: 5.8691 - val_loss: 5.9569 - val_ptsd_output_accuracy: 0.8148 - val_ptsd_output_loss: 0.5394\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - anxiety_output_loss: 6.7791 - loss: 7.1037 - ptsd_output_accuracy: 0.7097 - ptsd_output_loss: 0.6492 - val_anxiety_output_loss: 5.5525 - val_loss: 6.1043 - val_ptsd_output_accuracy: 0.7037 - val_ptsd_output_loss: 0.5807\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - anxiety_output_loss: 6.2135 - loss: 6.5279 - ptsd_output_accuracy: 0.7004 - ptsd_output_loss: 0.6290 - val_anxiety_output_loss: 2.2019 - val_loss: 2.3757 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.5243\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 6.2454 - loss: 6.5705 - ptsd_output_accuracy: 0.6686 - ptsd_output_loss: 0.6502 - val_anxiety_output_loss: 4.2950 - val_loss: 4.6675 - val_ptsd_output_accuracy: 0.8148 - val_ptsd_output_loss: 0.5000\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 3.5891 - loss: 3.9004 - ptsd_output_accuracy: 0.6423 - ptsd_output_loss: 0.6224 - val_anxiety_output_loss: 1.3776 - val_loss: 1.5517 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.4247\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 3.7981 - loss: 4.1305 - ptsd_output_accuracy: 0.6765 - ptsd_output_loss: 0.6648 - val_anxiety_output_loss: 1.8784 - val_loss: 1.9718 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.4242\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 3.4404 - loss: 3.7267 - ptsd_output_accuracy: 0.7810 - ptsd_output_loss: 0.5725 - val_anxiety_output_loss: 1.5525 - val_loss: 1.7753 - val_ptsd_output_accuracy: 0.7407 - val_ptsd_output_loss: 0.4575\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 3.7133 - loss: 3.9953 - ptsd_output_accuracy: 0.7662 - ptsd_output_loss: 0.5641 - val_anxiety_output_loss: 0.8955 - val_loss: 1.1297 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.3944\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 3.4139 - loss: 3.6757 - ptsd_output_accuracy: 0.7811 - ptsd_output_loss: 0.5236 - val_anxiety_output_loss: 1.8477 - val_loss: 1.9817 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.4459\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 4.5628 - loss: 4.7806 - ptsd_output_accuracy: 0.8298 - ptsd_output_loss: 0.4357 - val_anxiety_output_loss: 1.4397 - val_loss: 1.7018 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.4171\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 2.2521 - loss: 2.5306 - ptsd_output_accuracy: 0.7381 - ptsd_output_loss: 0.5570 - val_anxiety_output_loss: 1.1721 - val_loss: 1.4225 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.4364\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 2.5984 - loss: 2.8621 - ptsd_output_accuracy: 0.7689 - ptsd_output_loss: 0.5275 - val_anxiety_output_loss: 0.3919 - val_loss: 0.6162 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.4399\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - anxiety_output_loss: 2.6665 - loss: 2.8893 - ptsd_output_accuracy: 0.7789 - ptsd_output_loss: 0.4456 - val_anxiety_output_loss: 1.5282 - val_loss: 1.7180 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.3723\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 2.2916 - loss: 2.4937 - ptsd_output_accuracy: 0.8192 - ptsd_output_loss: 0.4043 - val_anxiety_output_loss: 0.5606 - val_loss: 0.6950 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.4189\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 2.5546 - loss: 2.7691 - ptsd_output_accuracy: 0.7734 - ptsd_output_loss: 0.4289 - val_anxiety_output_loss: 0.7143 - val_loss: 0.8383 - val_ptsd_output_accuracy: 1.0000 - val_ptsd_output_loss: 0.3363\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - anxiety_output_loss: 2.1066 - loss: 2.3462 - ptsd_output_accuracy: 0.7491 - ptsd_output_loss: 0.4793 - val_anxiety_output_loss: 1.3332 - val_loss: 1.6063 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.3956\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - anxiety_output_loss: 2.7708 - loss: 2.9695 - ptsd_output_accuracy: 0.8440 - ptsd_output_loss: 0.3973 - val_anxiety_output_loss: 0.7480 - val_loss: 0.9143 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.4139\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - anxiety_output_loss: 2.1649 - loss: 2.3857 - ptsd_output_accuracy: 0.8384 - ptsd_output_loss: 0.4416 - val_anxiety_output_loss: 0.5557 - val_loss: 0.7207 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.3582\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - anxiety_output_loss: 2.7623 - loss: 2.9567 - ptsd_output_accuracy: 0.8405 - ptsd_output_loss: 0.3887 - val_anxiety_output_loss: 0.5972 - val_loss: 0.7741 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.3421\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - anxiety_output_loss: 2.6054 - loss: 2.8231 - ptsd_output_accuracy: 0.8129 - ptsd_output_loss: 0.4353 - val_anxiety_output_loss: 0.6851 - val_loss: 0.8383 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.3087\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - anxiety_output_loss: 2.5126 - loss: 2.7162 - ptsd_output_accuracy: 0.8546 - ptsd_output_loss: 0.4071 - val_anxiety_output_loss: 0.8184 - val_loss: 1.0035 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3862\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - anxiety_output_loss: 2.1489 - loss: 2.3534 - ptsd_output_accuracy: 0.7935 - ptsd_output_loss: 0.4090 - val_anxiety_output_loss: 0.5115 - val_loss: 0.6761 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2959\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - anxiety_output_loss: 2.2270 - loss: 2.4422 - ptsd_output_accuracy: 0.8180 - ptsd_output_loss: 0.4303 - val_anxiety_output_loss: 0.5872 - val_loss: 0.7853 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2981\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - anxiety_output_loss: 2.1096 - loss: 2.3532 - ptsd_output_accuracy: 0.7475 - ptsd_output_loss: 0.4873 - val_anxiety_output_loss: 0.7076 - val_loss: 0.9488 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.3926\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - anxiety_output_loss: 2.6545 - loss: 2.8176 - ptsd_output_accuracy: 0.8985 - ptsd_output_loss: 0.3261 - val_anxiety_output_loss: 0.6598 - val_loss: 0.8475 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.3770\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - anxiety_output_loss: 2.8044 - loss: 3.0622 - ptsd_output_accuracy: 0.7926 - ptsd_output_loss: 0.5155 - val_anxiety_output_loss: 0.5394 - val_loss: 0.6545 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.3022\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - anxiety_output_loss: 1.7443 - loss: 1.9539 - ptsd_output_accuracy: 0.8251 - ptsd_output_loss: 0.4193 - val_anxiety_output_loss: 1.2470 - val_loss: 1.2990 - val_ptsd_output_accuracy: 0.8148 - val_ptsd_output_loss: 0.3394\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 2.0894 - loss: 2.2743 - ptsd_output_accuracy: 0.8307 - ptsd_output_loss: 0.3698 - val_anxiety_output_loss: 0.4319 - val_loss: 0.6337 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3107\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - anxiety_output_loss: 2.0712 - loss: 2.2672 - ptsd_output_accuracy: 0.7833 - ptsd_output_loss: 0.3921 - val_anxiety_output_loss: 0.4892 - val_loss: 0.6724 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.2964\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 1.7514 - loss: 1.9423 - ptsd_output_accuracy: 0.8805 - ptsd_output_loss: 0.3817 - val_anxiety_output_loss: 0.5228 - val_loss: 0.6781 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2826\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 1.7571 - loss: 1.9242 - ptsd_output_accuracy: 0.8783 - ptsd_output_loss: 0.3341 - val_anxiety_output_loss: 0.5790 - val_loss: 0.6891 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2781\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 2.4860 - loss: 2.6571 - ptsd_output_accuracy: 0.8966 - ptsd_output_loss: 0.3421 - val_anxiety_output_loss: 0.7010 - val_loss: 0.8580 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3444\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - anxiety_output_loss: 1.6560 - loss: 1.8915 - ptsd_output_accuracy: 0.7814 - ptsd_output_loss: 0.4710 - val_anxiety_output_loss: 1.5687 - val_loss: 1.7779 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.3258\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 2.0424 - loss: 2.2447 - ptsd_output_accuracy: 0.7937 - ptsd_output_loss: 0.4045 - val_anxiety_output_loss: 0.5817 - val_loss: 0.7459 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.2386\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 1.9976 - loss: 2.1393 - ptsd_output_accuracy: 0.9329 - ptsd_output_loss: 0.2835 - val_anxiety_output_loss: 0.8135 - val_loss: 0.9123 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3473\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - anxiety_output_loss: 1.8831 - loss: 2.0402 - ptsd_output_accuracy: 0.9159 - ptsd_output_loss: 0.3142 - val_anxiety_output_loss: 0.7215 - val_loss: 0.9516 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3713\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - anxiety_output_loss: 2.8511 - loss: 3.0578 - ptsd_output_accuracy: 0.8348 - ptsd_output_loss: 0.4134 - val_anxiety_output_loss: 0.3072 - val_loss: 0.4413 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2664\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - anxiety_output_loss: 2.7498 - loss: 2.9155 - ptsd_output_accuracy: 0.8862 - ptsd_output_loss: 0.3313 - val_anxiety_output_loss: 0.6785 - val_loss: 0.8008 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2531\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - anxiety_output_loss: 2.4460 - loss: 2.6261 - ptsd_output_accuracy: 0.8543 - ptsd_output_loss: 0.3602 - val_anxiety_output_loss: 0.5107 - val_loss: 0.6797 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.3221\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - anxiety_output_loss: 1.7763 - loss: 1.9643 - ptsd_output_accuracy: 0.7921 - ptsd_output_loss: 0.3761 - val_anxiety_output_loss: 0.7248 - val_loss: 0.9268 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.3150\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 1.7680 - loss: 1.9287 - ptsd_output_accuracy: 0.8484 - ptsd_output_loss: 0.3214 - val_anxiety_output_loss: 0.2613 - val_loss: 0.4326 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3652\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 2.5568 - loss: 2.7383 - ptsd_output_accuracy: 0.8281 - ptsd_output_loss: 0.3630 - val_anxiety_output_loss: 0.5402 - val_loss: 0.6725 - val_ptsd_output_accuracy: 0.8148 - val_ptsd_output_loss: 0.3147\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 1.9923 - loss: 2.1699 - ptsd_output_accuracy: 0.8231 - ptsd_output_loss: 0.3552 - val_anxiety_output_loss: 0.6616 - val_loss: 0.7375 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2322\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 2.3803 - loss: 2.5316 - ptsd_output_accuracy: 0.8884 - ptsd_output_loss: 0.3027 - val_anxiety_output_loss: 0.5058 - val_loss: 0.6723 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3314\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 2.5895 - loss: 2.7605 - ptsd_output_accuracy: 0.8241 - ptsd_output_loss: 0.3420 - val_anxiety_output_loss: 0.6031 - val_loss: 0.7407 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.3156\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - anxiety_output_loss: 2.0248 - loss: 2.1614 - ptsd_output_accuracy: 0.8664 - ptsd_output_loss: 0.2732 - val_anxiety_output_loss: 0.6070 - val_loss: 0.7073 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2905\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 1.7912 - loss: 1.9505 - ptsd_output_accuracy: 0.8878 - ptsd_output_loss: 0.3186 - val_anxiety_output_loss: 0.3206 - val_loss: 0.4799 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2688\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 1.7098 - loss: 1.9329 - ptsd_output_accuracy: 0.8045 - ptsd_output_loss: 0.4463 - val_anxiety_output_loss: 0.3497 - val_loss: 0.4456 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.1937\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 1.4671 - loss: 1.6633 - ptsd_output_accuracy: 0.8147 - ptsd_output_loss: 0.3925 - val_anxiety_output_loss: 0.1593 - val_loss: 0.2915 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.2842\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 1.7262 - loss: 1.9373 - ptsd_output_accuracy: 0.7275 - ptsd_output_loss: 0.4221 - val_anxiety_output_loss: 0.3519 - val_loss: 0.4819 - val_ptsd_output_accuracy: 0.8148 - val_ptsd_output_loss: 0.3386\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 1.8433 - loss: 2.0174 - ptsd_output_accuracy: 0.8531 - ptsd_output_loss: 0.3482 - val_anxiety_output_loss: 0.2752 - val_loss: 0.4319 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2560\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 1.7687 - loss: 1.9610 - ptsd_output_accuracy: 0.7967 - ptsd_output_loss: 0.3845 - val_anxiety_output_loss: 0.3900 - val_loss: 0.5464 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.2612\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 1.9666 - loss: 2.1163 - ptsd_output_accuracy: 0.8914 - ptsd_output_loss: 0.2993 - val_anxiety_output_loss: 0.2922 - val_loss: 0.4079 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2509\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - anxiety_output_loss: 1.9174 - loss: 2.0741 - ptsd_output_accuracy: 0.9153 - ptsd_output_loss: 0.3134 - val_anxiety_output_loss: 0.7755 - val_loss: 0.9760 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2180\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - anxiety_output_loss: 1.8423 - loss: 2.0106 - ptsd_output_accuracy: 0.8430 - ptsd_output_loss: 0.3367 - val_anxiety_output_loss: 0.2447 - val_loss: 0.3385 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.1839\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 2.2434 - loss: 2.3924 - ptsd_output_accuracy: 0.8832 - ptsd_output_loss: 0.2980 - val_anxiety_output_loss: 0.1124 - val_loss: 0.2607 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.2929\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 1.9632 - loss: 2.1287 - ptsd_output_accuracy: 0.8766 - ptsd_output_loss: 0.3310 - val_anxiety_output_loss: 0.4588 - val_loss: 0.6218 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2579\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - anxiety_output_loss: 1.3901 - loss: 1.5880 - ptsd_output_accuracy: 0.8106 - ptsd_output_loss: 0.3959 - val_anxiety_output_loss: 0.2085 - val_loss: 0.3268 - val_ptsd_output_accuracy: 1.0000 - val_ptsd_output_loss: 0.2316\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 1.9581 - loss: 2.0927 - ptsd_output_accuracy: 0.8911 - ptsd_output_loss: 0.2693 - val_anxiety_output_loss: 0.2709 - val_loss: 0.3466 - val_ptsd_output_accuracy: 1.0000 - val_ptsd_output_loss: 0.1484\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 2.2460 - loss: 2.4280 - ptsd_output_accuracy: 0.8132 - ptsd_output_loss: 0.3641 - val_anxiety_output_loss: 0.4495 - val_loss: 0.6310 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2750\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - anxiety_output_loss: 1.8631 - loss: 1.9863 - ptsd_output_accuracy: 0.8689 - ptsd_output_loss: 0.2465 - val_anxiety_output_loss: 0.3493 - val_loss: 0.5061 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2561\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 1.6453 - loss: 1.7821 - ptsd_output_accuracy: 0.8690 - ptsd_output_loss: 0.2736 - val_anxiety_output_loss: 0.4303 - val_loss: 0.6098 - val_ptsd_output_accuracy: 0.8148 - val_ptsd_output_loss: 0.2860\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - anxiety_output_loss: 1.6960 - loss: 1.8601 - ptsd_output_accuracy: 0.8527 - ptsd_output_loss: 0.3281 - val_anxiety_output_loss: 0.3984 - val_loss: 0.5357 - val_ptsd_output_accuracy: 0.8889 - val_ptsd_output_loss: 0.2872\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - anxiety_output_loss: 1.5663 - loss: 1.7655 - ptsd_output_accuracy: 0.8170 - ptsd_output_loss: 0.3984 - val_anxiety_output_loss: 0.6514 - val_loss: 0.8119 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2324\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - anxiety_output_loss: 1.6345 - loss: 1.8032 - ptsd_output_accuracy: 0.8512 - ptsd_output_loss: 0.3375 - val_anxiety_output_loss: 0.3900 - val_loss: 0.4913 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.1868\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - anxiety_output_loss: 1.8095 - loss: 1.9408 - ptsd_output_accuracy: 0.8759 - ptsd_output_loss: 0.2626 - val_anxiety_output_loss: 0.9656 - val_loss: 1.0198 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2181\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - anxiety_output_loss: 1.8168 - loss: 1.9703 - ptsd_output_accuracy: 0.8592 - ptsd_output_loss: 0.3070 - val_anxiety_output_loss: 0.5017 - val_loss: 0.6695 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2432\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - anxiety_output_loss: 1.7454 - loss: 1.9112 - ptsd_output_accuracy: 0.8588 - ptsd_output_loss: 0.3317 - val_anxiety_output_loss: 0.2814 - val_loss: 0.4123 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2717\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - anxiety_output_loss: 2.7110 - loss: 2.9868 - ptsd_output_accuracy: 0.7397 - ptsd_output_loss: 0.5517 - val_anxiety_output_loss: 0.7013 - val_loss: 0.7909 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2555\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - anxiety_output_loss: 1.6125 - loss: 1.8386 - ptsd_output_accuracy: 0.8461 - ptsd_output_loss: 0.4523 - val_anxiety_output_loss: 0.4190 - val_loss: 0.4865 - val_ptsd_output_accuracy: 1.0000 - val_ptsd_output_loss: 0.1764\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - anxiety_output_loss: 1.3956 - loss: 1.5391 - ptsd_output_accuracy: 0.8787 - ptsd_output_loss: 0.2871 - val_anxiety_output_loss: 0.7019 - val_loss: 0.8689 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2652\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - anxiety_output_loss: 2.0210 - loss: 2.1656 - ptsd_output_accuracy: 0.8690 - ptsd_output_loss: 0.2891 - val_anxiety_output_loss: 0.2945 - val_loss: 0.4485 - val_ptsd_output_accuracy: 0.8519 - val_ptsd_output_loss: 0.2669\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - anxiety_output_loss: 1.4175 - loss: 1.5488 - ptsd_output_accuracy: 0.8765 - ptsd_output_loss: 0.2625 - val_anxiety_output_loss: 0.7119 - val_loss: 0.8392 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.2391\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - anxiety_output_loss: 1.8339 - loss: 1.9491 - ptsd_output_accuracy: 0.8905 - ptsd_output_loss: 0.2305 - val_anxiety_output_loss: 0.2153 - val_loss: 0.3335 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2192\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - anxiety_output_loss: 2.0597 - loss: 2.1810 - ptsd_output_accuracy: 0.8783 - ptsd_output_loss: 0.2427 - val_anxiety_output_loss: 0.6052 - val_loss: 0.6655 - val_ptsd_output_accuracy: 0.9259 - val_ptsd_output_loss: 0.2112\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - anxiety_output_loss: 1.3275 - loss: 1.4829 - ptsd_output_accuracy: 0.8799 - ptsd_output_loss: 0.3108 - val_anxiety_output_loss: 0.7071 - val_loss: 0.7222 - val_ptsd_output_accuracy: 0.9630 - val_ptsd_output_loss: 0.1754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eb5be6a5190>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/HCC_Project/speechmodel.keras')"
      ],
      "metadata": {
        "id": "nk5koX8iOWBa"
      },
      "execution_count": 112,
      "outputs": []
    }
  ]
}