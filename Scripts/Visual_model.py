# -*- coding: utf-8 -*-
"""CGS616.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PVn5ziTxy2oEU96BLhQq40LTuSSe41Pc
"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score
from scipy.io import loadmat
from google.colab import drive

# Mount Google Drive (if your data is stored there)
drive.mount('/content/drive')

# Change this path to where your data is stored in Drive
data_path = '/content/drive/MyDrive/assignment'
os.chdir(data_path)

## 1. Data Loading and Preparation

class AnxietyDetectionPipeline:
    def __init__(self):
        self.train_labels = None
        self.dev_labels = None
        self.test_labels = None
        self.pipeline = None
        self.feature_importance = None

    def load_data(self):
        """Load all label files"""
        print("Loading label files...")
        self.train_labels = pd.read_csv('labels/train_split.csv')
        self.dev_labels = pd.read_csv('labels/dev_split.csv')
        self.test_labels = pd.read_csv('labels/test_split.csv')
        print("Label files loaded successfully.")
        # Check if 'Participant_ID' column exists in train_labels
        if 'Participant_ID' not in self.train_labels.columns:
            raise KeyError("The 'Participant_ID' column is missing in the train_split.csv file.")

# %%
# Initialize and test data loading
pipeline = AnxietyDetectionPipeline()
pipeline.load_data()

# Quick check of the loaded data
print("\nSample training labels:")
print(pipeline.train_labels.head())

## 2. Feature Loading and Exploration

def load_visual_features(self, pid):
    """Load visual features for a single participant"""
    base_path = f"{pid}_P/features/"
    features = {}

    # OpenFace features
    openface_path = base_path + f"{pid}_OpenFace2.1.0_Pose_gaze_AUs.csv"
    if os.path.exists(openface_path):
        features['openface'] = pd.read_csv(openface_path)

    # CNN features
    for model in ['ResNet', 'VGG', 'densenet201']:
        path = base_path + f"{pid}_CNN_{model}.mat" if 'CNN' in model else base_path + f"{pid}_{model}.csv"
        if os.path.exists(path):
            features[model.lower()] = loadmat(path) if path.endswith('.mat') else pd.read_csv(path)
    return features

# Add method to class
AnxietyDetectionPipeline.load_visual_features = load_visual_features

# %%
# Test feature loading with a sample participant
sample_pid = pipeline.train_labels['Participant_ID'].iloc[0]  # Get first participant
sample_features = pipeline.load_visual_features(sample_pid)

print("\nAvailable features for sample participant:")
print(sample_features.keys())

if 'openface' in sample_features:
    print("\nOpenFace features sample:")
    print(sample_features['openface'].head())

def load_visual_features(pid):
    features = {}
    base_path = f"{pid}_P/features/"

    # 1. Load OpenFace features (strict numeric check)
    openface_path = f"{base_path}{pid}_OpenFace2.1.0_Pose_gaze_AUs.csv"
    if os.path.exists(openface_path):
        df = pd.read_csv(openface_path)
        # Convert all AU columns to numeric, coercing errors
        au_cols = [col for col in df.columns if 'AU' in col and '_r' in col]
        df[au_cols] = df[au_cols].apply(pd.to_numeric, errors='coerce')
        features['openface'] = df.dropna(axis=1, how='all')  # Drop empty cols

    # 2. Process CNN features
    for model in ['ResNet', 'VGG', 'densenet201']:
        path = f"{base_path}{pid}_CNN_{model}.mat" if 'CNN' in model else f"{base_path}{pid}_{model}.csv"
        if os.path.exists(path):
            if path.endswith('.mat'):
                data = loadmat(path)
                # Extract numeric arrays from .mat file
                features[model.lower()] = {k: v for k, v in data.items()
                                        if not k.startswith('__') and np.isreal(v).all()}
            else:
                df = pd.read_csv(path)
                features[model.lower()] = df.select_dtypes(include=[np.number])
    return features

# In your load_data() method:
def load_data(self):
    self.train_labels = pd.read_csv('labels/train_split.csv')
    # Ensure PHQ_Score is numeric
    self.train_labels['PHQ_Score'] = pd.to_numeric(
        self.train_labels['PHQ_Score'],
        errors='coerce'
    ).fillna(0)  # Replace invalid with 0 or median

def extract_visual_features(features_dict):
    visual_features = {}

    # 1. OpenFace Features
    if 'openface' in features_dict:
        of = features_dict['openface']
        # Check for required columns
        required_cols = ['gaze_angle_x', 'pose_Rx', 'AU01_r']
        if all(col in of.columns for col in required_cols):
            visual_features.update({
                'gaze_avg_x': of['gaze_angle_x'].mean(),
                'pose_var': of[['pose_Rx', 'pose_Ry', 'pose_Rz']].var().mean(),
                **{f'{au}_mean': of[au].mean()
                   for au in of.columns if 'AU' in au and '_r' in au}
            })

    # 2. CNN Features
    for model in ['resnet', 'vgg', 'densenet201']:
        if model in features_dict:
            model_data = features_dict[model]
            if isinstance(model_data, dict):
                # Handle .mat file structure
                key = 'feature_vector' if 'feature_vector' in model_data else list(model_data.keys())[0]
                visual_features[f'{model}_avg'] = np.nanmean(model_data[key])
            elif isinstance(model_data, pd.DataFrame):
                visual_features[f'{model}_avg'] = model_data.values.mean()

    # Final validation
    if not visual_features:
        print("Warning: No features extracted")
    return {k: float(v) for k, v in visual_features.items() if np.isreal(v)}

def prepare_training_data(self):
    X, y = [], []
    failed_participants = []
    pid_arr = [300, 303, 304, 305, 307, 308, 309, 310, 313, 314, 315, 326, 327, 328, 329]
    # for pid in self.train_labels['Participant_ID']:
    for pid in pid_arr:
        try:
            features = self.load_visual_features(pid)
            if not features:
                continue

            feats = self.extract_visual_features(features)
            if not feats:
                continue

            X.append(feats)
            y.append(self.train_labels.loc[
                self.train_labels['Participant_ID'] == pid, 'PHQ_Score'
            ].values[0])
        except Exception as e:
            failed_participants.append(pid)
            continue

    print(f"Processed {len(X)} participants, failed {len(failed_participants)}")
    return pd.DataFrame(X).fillna(0), np.array(y)

# After loading data, add:
print("\n=== Data Verification ===")
print(f"Train labels shape: {pipeline.train_labels.shape}")
print(f"PHQ scores: {pipeline.train_labels['PHQ_Score'].describe()}")

# Check first participant's features
sample_pid = pipeline.train_labels['Participant_ID'][0]
sample_feats = pipeline.load_visual_features(sample_pid)
print("\nSample participant features:")
for k, v in sample_feats.items():
    if isinstance(v, pd.DataFrame):
        print(f"{k}: DataFrame {v.shape}")
    else:
        print(f"{k}: {type(v)}")

def debug_plot_features(participant_id):
    """Visualize raw feature distributions for debugging"""
    print("id dede",participant_id)
    features = pipeline.load_visual_features(participant_id)
    print("features dede",features)
    if 'openface' not in features:
        print("No OpenFace data available")
        return

    df = features['openface']
    plt.figure(figsize=(12, 6))

    # Plot first 5 AU columns
    au_cols = [c for c in df.columns if 'AU' in c and '_r' in c][:5]
    if au_cols:
        df[au_cols].plot(kind='box')
        plt.title(f'AU Distributions for Participant {participant_id}')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()
    else:
        print("No AU columns found")

# Run for first 3 participants
for pid in pipeline.train_labels['Participant_ID'][:1]:
    debug_plot_features(pid)

def analyze_feature_correlations(self):
    plt.close('all')  # Clear existing figures
    [pid]=300
    try:
        # 1. Data Collection
        all_openface = []
        for pid in self.train_labels['Participant_ID']:
            features = self.load_visual_features(pid)
            if 'openface' in features:
                au_cols = [col for col in features['openface'].columns
                         if col.startswith('AU') and '_r' in col and
                         pd.api.types.is_numeric_dtype(features['openface'][col])]
                if au_cols:
                    au_means = features['openface'][au_cols].mean()
                    au_means['pid'] = pid
                    all_openface.append(au_means)

        if not all_openface:
            raise ValueError("No valid OpenFace features found")

        # 2. Data Processing
        openface_df = pd.DataFrame(all_openface).merge(
            self.train_labels,
            left_on='pid',
            right_on='Participant_ID',
            how='left'
        )

        # 3. Ensure PHQ_Score is numeric
        openface_df['PHQ_Score'] = pd.to_numeric(openface_df['PHQ_Score'], errors='coerce')

        # 4. Select only numeric columns with variation
        numeric_df = openface_df.select_dtypes(include=[np.number])
        numeric_df = numeric_df.loc[:, numeric_df.nunique() > 1]

        if len(numeric_df.columns) == 0:
            raise ValueError("No numeric columns with variation found")

        # 5. First Visualization: Feature Distributions
        plt.figure(figsize=(12, 6))

        # Select only the first 5 numeric features (excluding pid/PHQ if needed)
        plot_features = [col for col in numeric_df.columns
                        if col not in ['pid', 'Participant_ID', 'PHQ_Score']][:5]

        if plot_features:
            numeric_df[plot_features].boxplot()
            plt.title('Distribution of Facial Features')
            plt.xticks(rotation=45)
            plt.tight_layout()
            plt.show()
        else:
            print("No features available for distribution plot")

        # 6. Correlation Analysis
        if 'PHQ_Score' not in numeric_df.columns:
            raise ValueError("PHQ_Score missing from numeric dataframe")

        correlations = numeric_df.corr()['PHQ_Score'].dropna().sort_values()

        # 7. Second Visualization: Top Correlations
        plt.figure(figsize=(10, 6))

        if len(correlations) > 0:
            top_features = pd.concat([correlations.head(5), correlations.tail(5)])
            colors = ['red' if x < 0 else 'green' for x in top_features]
            top_features.plot.barh(color=colors)
            plt.title('Top Correlations with PHQ Score')
            plt.xlabel('Correlation Coefficient')
            plt.grid(axis='x', alpha=0.3)
        else:
            plt.text(0.5, 0.5, 'No valid correlations found',
                    ha='center', va='center')
            plt.title('Correlation Analysis Results')

        plt.tight_layout()
        plt.show()

        return correlations

    except Exception as e:
        print(f"\nAnalysis Error: {str(e)}")

        # Error visualization
        plt.figure(figsize=(10, 4))
        plt.text(0.5, 0.5, f"Analysis Failed\nError: {str(e)}",
                ha='center', va='center', fontsize=12, color='red')
        plt.axis('off')
        plt.tight_layout()
        plt.show()

        return None

def extract_visual_features(self, features_dict):
    visual_features = {}

    # OpenFace features
    if 'openface' in features_dict:
        of = features_dict['openface']
        # Gaze features
        visual_features.update({
            'gaze_avg_x': of['gaze_angle_x'].mean(),
            'gaze_var_y': of['gaze_angle_y'].var(),
            'pose_var': of[['pose_Rx', 'pose_Ry', 'pose_Rz']].var().mean()
        })

        # Action Units
        au_columns = [col for col in of.columns if col.startswith('AU') and '_r' in col]
        for au in au_columns:
            visual_features.update({
                f'{au}_mean': of[au].mean(),
                f'{au}_var': of[au].var()
            })

    # CNN features with proper type checking
    for model in ['resnet', 'vgg', 'densenet201']:
        if model in features_dict:
            try:
                # Handle different CNN feature formats
                if isinstance(features_dict[model], dict):
                    # MATLAB .mat file structure
                    cnn_data = features_dict[model].get('feature_vector', features_dict[model].get('features'))
                    if cnn_data is not None:
                        if isinstance(cnn_data, (np.ndarray, list)):
                            visual_features[f'{model}_feat_avg'] = np.nanmean(cnn_data)
                        else:
                            print(f"Unexpected data type for {model} features in dict")
                elif isinstance(features_dict[model], (pd.DataFrame, np.ndarray)):
                    # CSV or numpy array - first ensure we have numeric data
                    data = features_dict[model].values if isinstance(features_dict[model], pd.DataFrame) else features_dict[model]
                    # Filter out non-numeric columns if DataFrame
                    if isinstance(features_dict[model], pd.DataFrame):
                        data = features_dict[model].select_dtypes(include=[np.number]).values
                    # Convert to float and handle strings that can't be converted
                    try:
                        float_data = data.astype(float)
                        visual_features[f'{model}_feat_avg'] = np.nanmean(float_data)
                    except (ValueError, TypeError):
                        print(f"Non-convertible data in {model} features")
                        visual_features[f'{model}_feat_avg'] = np.nan
                else:
                    print(f"Unsupported format for {model} features: {type(features_dict[model])}")
            except Exception as e:
                print(f"Error processing {model} features: {str(e)}")
                visual_features[f'{model}_feat_avg'] = np.nan

    return visual_features

def prepare_training_data(self):
    """Prepare training data with robust error handling"""
    X_train, y_train = [], []
    for pid in self.train_labels['Participant_ID']:
        features = load_visual_features(pid)
        if not features:
            continue

        try:
            visual_feats = extract_visual_features(self, features)
            if not visual_feats:
                continue

            # Convert all values to numeric, carefully handling errors
            processed_feats = {}
            for k, v in visual_feats.items():
                try:
                    # Skip string values that aren't numeric
                    if isinstance(v, str):
                        if v.replace('.', '', 1).isdigit():
                            processed_feats[k] = float(v)
                        continue
                    processed_feats[k] = float(v)
                except (ValueError, TypeError):
                    continue
            if processed_feats:  # Only add if we have valid features
                X_train.append(processed_feats)
                y_train.append(self.train_labels.loc[
                    self.train_labels['Participant_ID'] == pid, 'PHQ_Score'].values[0])
        except Exception as e:
            print(f"Error processing participant {pid}: {str(e)}")
            continue
    print(X_train)
    if not X_train:
        raise ValueError("No valid training data could be processed")

    X_df = pd.DataFrame(X_train)

    # Ensure all columns are numeric (coerce errors to NaN)
    X_df = X_df.apply(pd.to_numeric, errors='coerce')

    # Fill NaNs with column means (only for columns with some valid values)
    valid_cols = X_df.columns[X_df.notna().any()]
    X_df[valid_cols] = X_df[valid_cols].fillna(X_df[valid_cols].mean())

    return X_df, np.array(y_train)

def plot_feature_importance(self, top_n=15):
    """Visualize feature importance"""
    plt.figure(figsize=(10, 6))
    plt.barh(
        self.feature_importance['feature'].head(top_n)[::-1],  # Reverse for descending order
        self.feature_importance['importance'].head(top_n)[::-1])
    plt.title('Top Visual Features Predicting Anxiety')
    plt.xlabel('Importance')
    plt.ylabel('Visual Feature')
    plt.tight_layout()
    plt.show()

def build_model(self):
    """Build and evaluate the machine learning pipeline"""
    X_train, y_train = prepare_training_data(self)

    self.pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('regressor', RandomForestRegressor(
            n_estimators=100,
            random_state=42,
            n_jobs=-1  # Use all available cores
        ))
    ])

    # Cross-validation
    scores = cross_val_score(
        self.pipeline, X_train, y_train,
        cv=5, scoring='neg_mean_squared_error')
    print(f"Average RMSE: {np.sqrt(-scores.mean())} (±{np.sqrt(-scores.std())})")

    # Fit final model
    self.pipeline.fit(X_train, y_train)

    # Feature importance
    importances = self.pipeline.named_steps['regressor'].feature_importances_
    self.feature_importance = pd.DataFrame({
        'feature': X_train.columns,
        'importance': importances
    }).sort_values('importance', ascending=False)

    print("\nTop visual features predicting anxiety:")
    print(self.feature_importance.head(10))

    plot_feature_importance(self)

def plot_predictions_vs_actual(self, y_true, y_pred):
    """Plot actual vs predicted values with regression line"""
    plt.figure(figsize=(8, 6))
    plt.scatter(y_true, y_pred, alpha=0.6)

    # Add regression line
    m, b = np.polyfit(y_true, y_pred, 1)
    plt.plot(y_true, m*y_true + b, 'r--')

    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'k:')
    plt.xlabel('Actual PHQ Score')
    plt.ylabel('Predicted PHQ Score')
    plt.title('Actual vs Predicted Anxiety Levels')
    plt.grid(True)
    plt.show()

def evaluate_on_test(self):
    """Evaluate model performance on test set"""
    if not hasattr(self, 'pipeline') or self.pipeline is None:
        raise ValueError("Model has not been trained yet. Call build_model() first.")

    X_test, y_test = [], []
    pid_arr = [600, 604, 605, 606, 615, 618, 619, 620, 624, 631, 634, 635, 649, 655, 705, 716]
    # for pid in self.test_labels['Participant_ID']:
    for pid in pid_arr:
        features = load_visual_features(pid)
        if not features:
            continue
        try:
            visual_feats = extract_visual_features(self, features)
            if not visual_feats:
                continue

            # Convert all values to numeric
            processed_feats = {}
            for k, v in visual_feats.items():
                try:
                    processed_feats[k] = float(v)
                except (ValueError, TypeError):
                    processed_feats[k] = np.nan

            X_test.append(processed_feats)
            y_test.append(
                self.test_labels[self.test_labels['Participant_ID'] == pid]['PHQ_Score'].values[0])
        except Exception as e:
            print(f"Error processing participant {pid}: {str(e)}")
            continue
    X_test_df = pd.DataFrame(X_test)

    # Ensure same columns as training data
    X_test_df = X_test_df.reindex(columns=self.pipeline.feature_names_in_, fill_value=0)

    # Convert all columns to numeric, coercing errors
    X_test_df = X_test_df.apply(pd.to_numeric, errors='coerce')
    # Fill NaNs with column means from training - FIXED HERE
    # Create a dictionary of column means from the scaler
    fill_values = dict(zip(self.pipeline.feature_names_in_,
                          self.pipeline.named_steps['scaler'].mean_))
    print(fill_values)
    X_test_df = X_test_df.fillna(fill_values)

    y_test = np.array(y_test)
    # Evaluation
    test_score = self.pipeline.score(X_test_df, y_test)
    print(f"\nTest R-squared: {test_score:.3f}")
    # Error analysis
    predictions = self.pipeline.predict(X_test_df)
    print(f"y_test {y_test.shape}, predictions {predictions.shape}, x_test {X_test_df.shape}")
    self.plot_predictions_vs_actual(y_test, predictions)

    return test_score, predictions, y_test

# Add methods to class
AnxietyDetectionPipeline.evaluate_on_test = evaluate_on_test
AnxietyDetectionPipeline.plot_predictions_vs_actual = plot_predictions_vs_actual

class RealTimeAnxietyPredictor:
    """Class for real-time anxiety prediction"""
    def __init__(self, model):
        if not hasattr(model, 'predict'):
            raise ValueError("Model must be a fitted scikit-learn predictor")
        self.model = model
        self.feature_buffer = []
        self.window_size = 30  # 30 frames (~1 second at 30fps)
        self.required_features = model.feature_names_in_  # Get features from trained model

    def process_frame(self, frame_features):
        """Process a single frame's visual features"""
        self.feature_buffer.append(frame_features)
        if len(self.feature_buffer) > self.window_size:
            self.feature_buffer.pop(0)

        if len(self.feature_buffer) < self.window_size:
            return None  # Not enough frames yet

        window_features = self._calculate_window_features()
        return self.model.predict([window_features])[0]

    def _calculate_window_features(self):
        """Convert frame buffer into window features matching training format"""
        window_df = pd.DataFrame(self.feature_buffer)

        # Calculate all features used in training
        features = {}
        for feat in self.required_features:
            if feat in window_df.columns:
                if '_mean' in feat:
                    base_feat = feat.replace('_mean', '')
                    features[feat] = window_df[base_feat].mean()
                elif '_var' in feat:
                    base_feat = feat.replace('_var', '')
                    features[feat] = window_df[base_feat].var()
                else:
                    features[feat] = window_df[feat].iloc[-1]  # Use latest value

        # Ensure all required features are present
        return {k: features.get(k, 0) for k in self.required_features}

# # Example usage flow:
# # 1. Initialize pipeline
# pipeline = AnxietyDetectionPipeline()
# pipeline.load_data()

# # 2. Train model
# print("\nTraining model...", pipeline)
# build_model(pipeline)

# # 3. Evaluate on test set
# print("\nEvaluating on test set...")
# test_score, predictions, y_true = evaluate_on_test(pipeline)

# # 4. Initialize real-time predictor (only after model is trained)
# print("\nInitializing real-time predictor...")
# rt_predictor = RealTimeAnxietyPredictor(pipeline.pipeline)
# print("Real-time predictor ready.")

# SAVING THE MODEL
import pickle

# 1. Initialize pipeline
pipeline = AnxietyDetectionPipeline()
pipeline.load_data()


# 2. Train model
print("\nTraining model...", pipeline)
build_model(pipeline)

# ✅ Save the trained model to a file
with open('anxiety_model.pkl', 'wb') as f:
    pickle.dump(pipeline, f)
print("Model saved to 'anxiety_model.pkl'.")

# 3. Evaluate on test set
print("\nEvaluating on test set...")
test_score, predictions, y_true = evaluate_on_test(pipeline)

# 4. Initialize real-time predictor (only after model is trained)
print("\nInitializing real-time predictor...")
rt_predictor = RealTimeAnxietyPredictor(pipeline.pipeline)
print("Real-time predictor ready.")

# LOADING THE MODEL
# import pickle

# with open('anxiety_model.pkl', 'rb') as f:
#     trained_pipeline = pickle.load(f)

# pipeline = trained_pipeline

# print("\nEvaluating on test set...")
# test_score, predictions, y_true = evaluate_on_test(pipeline)

# print("\nInitializing real-time predictor...")
# rt_predictor = RealTimeAnxietyPredictor(pipeline.pipeline)
# print("Real-time predictor ready.")